{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer:\n",
    "It's info from our dataset. Every feature/column is a input nod \n",
    "### Hidden Layer:\n",
    "### Output Layer:\n",
    "### Neuron: \n",
    "Takes info from previous layer, takes weighted sum of that info as a bias term, passes it through activation value and passes info to the next layer (recieving signal, processing signal, deciding how much signal pass to next layer)\n",
    "### Weight:\n",
    "### Activation Function:\n",
    "### Node Map:\n",
    "### Perceptron:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "#### Your Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   0   0  1\n",
       "1   1   0  1\n",
       "2   0   1  1\n",
       "3   1   1  0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_output = [[0], [1], [0], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08340853],\n",
       "       [ 0.21813962],\n",
       "       [-0.64526674]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = 2 * np.random.random((3,1)) - 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEIGHTS after training\n",
      "[[ 6.62427637]\n",
      " [-1.14438037]\n",
      " [-3.23197482]]\n",
      "OUTPUT after training\n",
      "[[0.03799889]\n",
      " [0.9674465 ]\n",
      " [0.01242301]\n",
      " [0.9958438 ]]\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1000):\n",
    "    weighted_sum = np.dot(df, weights)\n",
    "    \n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    error = correct_output - activated_output\n",
    "    adjustments = error * sigmoid_der(weighted_sum)\n",
    "    \n",
    "    weights += np.dot(df.T, adjustments)\n",
    "    \n",
    "print('WEIGHTS after training')\n",
    "print(weights)\n",
    "print('OUTPUT after training')\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetes['Outcome'].value_counts().plot(kind = \"barh\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Outcome\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = diabetes.drop('Outcome', axis=1)\n",
    "Y = diabetes['Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "\n",
    "transformer = Normalizer()\n",
    "\n",
    "# feats = list(diabetes)[:-1]\n",
    "\n",
    "X = transformer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.033552</td>\n",
       "      <td>0.827625</td>\n",
       "      <td>0.402628</td>\n",
       "      <td>0.195722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.279603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.008424</td>\n",
       "      <td>0.716040</td>\n",
       "      <td>0.555984</td>\n",
       "      <td>0.244296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224079</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.261144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.040398</td>\n",
       "      <td>0.924097</td>\n",
       "      <td>0.323181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.161591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.006612</td>\n",
       "      <td>0.588467</td>\n",
       "      <td>0.436392</td>\n",
       "      <td>0.152076</td>\n",
       "      <td>0.621527</td>\n",
       "      <td>0.185797</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.138852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.596386</td>\n",
       "      <td>0.174127</td>\n",
       "      <td>0.152361</td>\n",
       "      <td>0.731335</td>\n",
       "      <td>0.187622</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.143655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>0.427443</td>\n",
       "      <td>0.321640</td>\n",
       "      <td>0.203141</td>\n",
       "      <td>0.761779</td>\n",
       "      <td>0.139236</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.266623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>0.013304</td>\n",
       "      <td>0.811526</td>\n",
       "      <td>0.465629</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244788</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>0.026915</td>\n",
       "      <td>0.651352</td>\n",
       "      <td>0.387582</td>\n",
       "      <td>0.123811</td>\n",
       "      <td>0.602905</td>\n",
       "      <td>0.141037</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.161492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.838285</td>\n",
       "      <td>0.399184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200257</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.312694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>0.007915</td>\n",
       "      <td>0.736052</td>\n",
       "      <td>0.554018</td>\n",
       "      <td>0.245351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240602</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.182034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0       0.033552  0.827625       0.402628       0.195722  0.000000  0.187893   \n",
       "1       0.008424  0.716040       0.555984       0.244296  0.000000  0.224079   \n",
       "2       0.040398  0.924097       0.323181       0.000000  0.000000  0.117658   \n",
       "3       0.006612  0.588467       0.436392       0.152076  0.621527  0.185797   \n",
       "4       0.000000  0.596386       0.174127       0.152361  0.731335  0.187622   \n",
       "..           ...       ...            ...            ...       ...       ...   \n",
       "763     0.042321  0.427443       0.321640       0.203141  0.761779  0.139236   \n",
       "764     0.013304  0.811526       0.465629       0.179600  0.000000  0.244788   \n",
       "765     0.026915  0.651352       0.387582       0.123811  0.602905  0.141037   \n",
       "766     0.006653  0.838285       0.399184       0.000000  0.000000  0.200257   \n",
       "767     0.007915  0.736052       0.554018       0.245351  0.000000  0.240602   \n",
       "\n",
       "     DiabetesPedigreeFunction       Age  \n",
       "0                    0.003506  0.279603  \n",
       "1                    0.002957  0.261144  \n",
       "2                    0.003393  0.161591  \n",
       "3                    0.001104  0.138852  \n",
       "4                    0.009960  0.143655  \n",
       "..                        ...       ...  \n",
       "763                  0.000724  0.266623  \n",
       "764                  0.002262  0.179600  \n",
       "765                  0.001319  0.161492  \n",
       "766                  0.002322  0.312694  \n",
       "767                  0.002493  0.182034  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(X, columns=diabetes.drop(\"Outcome\",axis = 1).columns)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 8), (154, 8), (614,), (154,))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, stratify = target, random_state = 42)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "##### Update this Class #####\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, niter = 10):\n",
    "        self.niter = niter\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        sx = sigmoid(x)\n",
    "        return sx * (1-sx)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "\n",
    "        # Randomly Initialize Weights\n",
    "        self.weight = np.zeros(1 + X_train.shape[1])\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            \n",
    "            # Weighted sum of inputs / weights\n",
    "            weighted_sum = np.dot(X_train, self.weight)\n",
    "\n",
    "            # Activate!\n",
    "            activated_output = sigmoid(weighted_sum)\n",
    "\n",
    "            # Cac error\n",
    "            error = X_test - activated_output\n",
    "\n",
    "            # Update the Weights\n",
    "            weights += np.dot(X_train.T, adjustments)\n",
    "            \n",
    "    def net_input(self, X_tain):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (614,8) and (9,) not aligned: 8 (dim 1) != 9 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-2a9f9c25a3a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'o'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Number of misclassifications'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-80-115db62ad9db>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Weighted sum of inputs / weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mweighted_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;31m# Activate!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (614,8) and (9,) not aligned: 8 (dim 1) != 9 (dim 0)"
     ]
    }
   ],
   "source": [
    "pn = Perceptron(10)\n",
    "pn.fit(X_train, Y_train)\n",
    "plt.plot(range(1, len(pn.errors) + 1), pn.errors, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
